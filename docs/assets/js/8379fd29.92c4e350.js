"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[7753],{28453:(e,r,n)=>{n.d(r,{R:()=>s,x:()=>t});var i=n(96540);const o={},a=i.createContext(o);function s(e){const r=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function t(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(a.Provider,{value:r},e.children)}},57887:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>t,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"api/functions/transformRgbToDepthUv","title":"Function: transformRgbToDepthUv()","description":"transformRgbToDepthUv(rgbUv, renderCameraWorldFromClip, depthCameraClipFromWorld, xrDeviceCamera?) number; v: number; \\\\}","source":"@site/docs/api/functions/transformRgbToDepthUv.md","sourceDirName":"api/functions","slug":"/api/functions/transformRgbToDepthUv","permalink":"/docs/api/functions/transformRgbToDepthUv","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"typedocSidebar","previous":{"title":"showReticleOnDepthMesh","permalink":"/docs/api/functions/showReticleOnDepthMesh"},"next":{"title":"transformRgbToRenderCameraClip","permalink":"/docs/api/functions/transformRgbToRenderCameraClip"}}');var o=n(74848),a=n(28453);const s={},t="Function: transformRgbToDepthUv()",c={},d=[{value:"Parameters",id:"parameters",level:2},{value:"rgbUv",id:"rgbuv",level:3},{value:"u",id:"u",level:4},{value:"v",id:"v",level:4},{value:"renderCameraWorldFromClip",id:"rendercameraworldfromclip",level:3},{value:"depthCameraClipFromWorld",id:"depthcameraclipfromworld",level:3},{value:"xrDeviceCamera?",id:"xrdevicecamera",level:3},{value:"Returns",id:"returns",level:2}];function l(e){const r={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",strong:"strong",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(r.header,{children:(0,o.jsx)(r.h1,{id:"function-transformrgbtodepthuv",children:"Function: transformRgbToDepthUv()"})}),"\n",(0,o.jsxs)(r.blockquote,{children:["\n",(0,o.jsxs)(r.p,{children:[(0,o.jsx)(r.strong,{children:"transformRgbToDepthUv"}),"(",(0,o.jsx)(r.code,{children:"rgbUv"}),", ",(0,o.jsx)(r.code,{children:"renderCameraWorldFromClip"}),", ",(0,o.jsx)(r.code,{children:"depthCameraClipFromWorld"}),", ",(0,o.jsx)(r.code,{children:"xrDeviceCamera?"}),"): ",(0,o.jsx)(r.code,{children:"null"})," | { ",(0,o.jsx)(r.code,{children:"u"}),": ",(0,o.jsx)(r.code,{children:"number"}),"; ",(0,o.jsx)(r.code,{children:"v"}),": ",(0,o.jsx)(r.code,{children:"number"}),"; }"]}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["Defined in: ",(0,o.jsx)(r.a,{href:"https://github.com/google/xrblocks/blob/main/src/camera/CameraUtils.ts#L110",children:"src/camera/CameraUtils.ts:110"})]}),"\n",(0,o.jsx)(r.p,{children:"Maps a UV coordinate from a RGB space to a destination depth space,\napplying Brown-Conrady distortion and affine transformations based on\naspect ratios. If the simulator camera is used, no transformation is applied."}),"\n",(0,o.jsx)(r.h2,{id:"parameters",children:"Parameters"}),"\n",(0,o.jsx)(r.h3,{id:"rgbuv",children:"rgbUv"}),"\n",(0,o.jsx)(r.p,{children:"The RGB UV coordinate, e.g., { u: 0.5, v: 0.5 }."}),"\n",(0,o.jsx)(r.h4,{id:"u",children:"u"}),"\n",(0,o.jsx)(r.p,{children:(0,o.jsx)(r.code,{children:"number"})}),"\n",(0,o.jsx)(r.h4,{id:"v",children:"v"}),"\n",(0,o.jsx)(r.p,{children:(0,o.jsx)(r.code,{children:"number"})}),"\n",(0,o.jsx)(r.h3,{id:"rendercameraworldfromclip",children:"renderCameraWorldFromClip"}),"\n",(0,o.jsx)(r.p,{children:(0,o.jsx)(r.a,{href:"https://threejs.org/docs/#api/en/math/Matrix4",children:(0,o.jsx)(r.code,{children:"Matrix4"})})}),"\n",(0,o.jsx)(r.p,{children:"Render camera world from clip, i.e. inverse of the View Projection matrix."}),"\n",(0,o.jsx)(r.h3,{id:"depthcameraclipfromworld",children:"depthCameraClipFromWorld"}),"\n",(0,o.jsx)(r.p,{children:(0,o.jsx)(r.a,{href:"https://threejs.org/docs/#api/en/math/Matrix4",children:(0,o.jsx)(r.code,{children:"Matrix4"})})}),"\n",(0,o.jsx)(r.p,{children:"Depth camera clip from world, i.e."}),"\n",(0,o.jsx)(r.h3,{id:"xrdevicecamera",children:"xrDeviceCamera?"}),"\n",(0,o.jsx)(r.p,{children:(0,o.jsx)(r.a,{href:"/docs/api/classes/XRDeviceCamera",children:(0,o.jsx)(r.code,{children:"XRDeviceCamera"})})}),"\n",(0,o.jsx)(r.p,{children:"The device camera instance."}),"\n",(0,o.jsx)(r.h2,{id:"returns",children:"Returns"}),"\n",(0,o.jsxs)(r.p,{children:[(0,o.jsx)(r.code,{children:"null"})," | { ",(0,o.jsx)(r.code,{children:"u"}),": ",(0,o.jsx)(r.code,{children:"number"}),"; ",(0,o.jsx)(r.code,{children:"v"}),": ",(0,o.jsx)(r.code,{children:"number"}),"; }"]}),"\n",(0,o.jsx)(r.p,{children:"The transformed UV coordinate in the depth image space, or null if\ninputs are invalid."})]})}function h(e={}){const{wrapper:r}={...(0,a.R)(),...e.components};return r?(0,o.jsx)(r,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}}}]);